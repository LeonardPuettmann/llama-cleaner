{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import *\n",
    "\n",
    "def load_json_data(folder_path, key):\n",
    "    data = []\n",
    "    for file_path in glob.glob(folder_path + '/*.json'):\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "            data.extend(json_data[key])\n",
    "    return data\n",
    "\n",
    "raw_pages = load_json_data(\"../data_prep/data\", key=\"ocr_results\")\n",
    "cleaned_pages = load_json_data(\"../data_prep/data\", key=\"cleaned_pages\")\n",
    "\n",
    "test_size = 0.2\n",
    "train_size = int(len(cleaned_pages) * (1 - test_size))\n",
    "train_raw_pages, test_raw_pages = raw_pages[:train_size], raw_pages[train_size:]\n",
    "train_cleaned_pages, test_cleaned_pages = cleaned_pages[:train_size], cleaned_pages[train_size:]\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_dict({\"raw_pages\": train_raw_pages[:len(train_cleaned_pages)], \"cleaned_pages\": train_cleaned_pages}),\n",
    "    'test': Dataset.from_dict({\"raw_pages\": test_raw_pages[:len(test_cleaned_pages)], \"cleaned_pages\": test_cleaned_pages})\n",
    "})\n",
    "\n",
    "base_model = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "\n",
    "instruction = \"\"\"\n",
    "Du bist ein Experte für Textbereinigung. Deine Aufgabe ist es, einen Eingabetext zu bereinigen, der aus einem PDF-Dokument extrahiert wurde. Der Inhalt ist immer nur von einer einzelnen Seite, es sollte also nicht zu viel Text auf einmal sein. Es ist sehr wichtig, dass keine Daten und Informationen verloren gehen und dass die Originaltexte in keiner Weise verändert werden!\n",
    "Antworte ausschließlich in Deutsch und keiner anderen Sprache.\n",
    "\n",
    "Du hast die folgenden Aufgaben:\n",
    "- Entferne alle seltsamen Textteile und Sonderzeichen.\n",
    "- Entferne alle unnötigen Leerzeichen und Zeilenumbrüche.\n",
    "- Organisiere die Formatierung.\n",
    "- Korrektur von Rechtschreibfehlern.\n",
    "- Handling von Formatierungsfehlern.\n",
    "\n",
    "Gib nur den bereinigten und formatierten Text zurück und nichts anderes! Füge keinen eigenen Text hinzu! Achte auf Vollständigkeit, es darf kein Inhalt verloren gehen und es muss alles 100 % vollständig sein!\n",
    "\"\"\"\n",
    "\n",
    "def format_chat_template(row):\n",
    "    \n",
    "    row_json = [{\"role\": \"system\", \"content\": instruction},\n",
    "               {\"role\": \"user\", \"content\": row[\"raw_pages\"]},\n",
    "               {\"role\": \"assistant\", \"content\": row[\"cleaned_pages\"]}]\n",
    "    \n",
    "    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(\n",
    "    format_chat_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
